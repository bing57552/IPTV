import requests
import time
from concurrent.futures import ThreadPoolExecutor

# 1. æ‰©å……å…¨çƒæºï¼šæ¶µç›–åŒ—ç¾ã€äºšæ´²ï¼ˆæ–°é©¬æ³°ï¼‰ã€æ¬§æ´²åŠä¸­æ–‡å½±è§†ä¸“é¡¹
SOURCES = {
    "north_america": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/america.m3u",
    "europe": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/europe.m3u",
    "asia_chinese": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/asia.m3u",
    "southeast_asia": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/singapore_malaysia.m3u",
    "itv_movie_special": "https://itvlist.cc/itv.m3u",
    "global_zh": "https://iptv-org.github.io/iptv/languages/zho.m3u",
    "fanmingming_live": "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv4.m3u"
}

# 2. ç”µå½±ä¸ç”µè§†å‰§å…³é”®è¯è¿‡æ»¤æ¸…å•ï¼Œç¡®ä¿å†…å®¹ç²¾å‡†
KEYWORDS = ["ç”µå½±", "ç”µè§†å‰§", "å‰§åœº", "å½±é™¢", "TVB", "ç¿¡ç¿ ", "æ˜Ÿæ²³", "åä¸½", "Drama", "Movie", "ä¸­æ–‡", "åè¯­", "Channel 8", "Ué¢‘é“"]

def check_url(item):
    name_info, url = item
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚å¤´ï¼Œè§£å†³éƒ¨åˆ†æºæ–­æµæˆ–éŸ³ç”»ä¸åŒæ­¥é—®é¢˜
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    try:
        start_time = time.time()
        # é’ˆå¯¹æµ·å¤–æºï¼Œå°†è¶…æ—¶ä»1.2sæ”¾å®½è‡³2.0sï¼Œé˜²æ­¢è¯¯åˆ ä¼˜è´¨é•¿é€”çº¿è·¯
        response = requests.head(url, headers=headers, timeout=2.0, allow_redirects=True)
        end_time = time.time()
        
        if response.status_code == 200:
            return {"name": name_info, "url": url, "speed": end_time - start_time}
    except:
        pass
    return None

def main():
    unique_channels = {}
    
    for filename, url in SOURCES.items():
        try:
            print(f"ğŸŒ æ­£åœ¨åŒæ­¥å…¨çƒå½±è§†èµ„æº: {filename}")
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            lines = r.text.split('\n')
            temp_list = []
            
            for i in range(len(lines)):
                if "#EXTINF" in lines[i] and i + 1 < len(lines):
                    name_info = lines[i].strip()
                    link = lines[i+1].strip()
                    
                    if link.startswith('http'):
                        clean_name = name_info.split(',')[-1].strip()
                        # å…³é”®è¯ç­›é€‰ï¼šä»…ä¿ç•™äºšæ´²/æ¬§æ´²çš„ä¸­æ–‡ç”µå½±å’Œç”µè§†å‰§
                        if any(kw.lower() in clean_name.lower() for kw in KEYWORDS):
                            temp_list.append((name_info, link))

            # å¹¶å‘æµ‹é€Ÿç­›é€‰
            with ThreadPoolExecutor(max_workers=30) as executor:
                results = list(executor.map(check_url, temp_list))

            # æ™ºèƒ½å»é‡ï¼šä¿ç•™åŒåé¢‘é“ä¸­å»¶è¿Ÿæœ€ä½çš„æº
            for res in results:
                if res:
                    c_name = res["name"].split(',')[-1].strip()
                    if c_name not in unique_channels or res["speed"] < unique_channels[c_name]["speed"]:
                        unique_channels[c_name] = res
            
            print(f"âœ… {filename} ç­›é€‰å®Œæˆ")
        except Exception as e:
            print(f"âŒ {filename} åŒæ­¥å¤±è´¥: {e}")

    # æ±‡æ€»ç”Ÿæˆæœ€ç»ˆçš„ all.m3u æ–‡ä»¶
    final_list = []
    for res in unique_channels.values():
        final_list.append(f"{res['name']}\n{res['url']}")

    with open("all.m3u", "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n" + "\n".join(final_list))
    
    print(f"\nğŸš€ å¤„ç†å®Œæˆï¼å·²ç”Ÿæˆå…¨è¦†ç›–å½±è§†åˆ—è¡¨ã€‚å½“å‰ç¨³å®šé¢‘é“æ€»æ•°: {len(final_list)}")

if __name__ == "__main__":
    main()


