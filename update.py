import requests
import time
from concurrent.futures import ThreadPoolExecutor

# 1. æ•´åˆäºšæ´²ã€æ¬§æ´²ã€åŒ—ç¾åŠå½±è§†ä¸“é¡¹æº
SOURCES = {
    "north_america": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/america.m3u",
    "europe": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/europe.m3u",
    "asia_chinese": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/asia.m3u",
    "southeast_asia": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/singapore_malaysia.m3u",
    "itv_movie_special": "https://itvlist.cc/itv.m3u",
    "global_chinese": "https://iptv-org.github.io/iptv/languages/zho.m3u",
    "live_hd": "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv4.m3u"
}

# 2. ç”µå½±ä¸ç”µè§†å‰§å…³é”®è¯è¿‡æ»¤æ¸…å•
KEYWORDS = ["ç”µå½±", "ç”µè§†å‰§", "å‰§åœº", "å½±é™¢", "TVB", "ç¿¡ç¿ ", "æ˜Ÿæ²³", "åä¸½", "Drama", "Movie", "ä¸­æ–‡", "åè¯­", "Channel 8", "Ué¢‘é“"]

def check_url(item):
    name_info, url = item
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚å¤´ï¼Œå‡å°‘æ–­æµä¸åŒæ­¥é—®é¢˜
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    try:
        start_time = time.time()
        # å°†è¶…æ—¶æ”¾å®½è‡³ 2.0s ä»¥é€‚é…æµ·å¤–ç‰©ç†å»¶è¿Ÿ
        response = requests.head(url, headers=headers, timeout=2.0, allow_redirects=True)
        end_time = time.time()
        
        if response.status_code == 200:
            return {"name": name_info, "url": url, "speed": end_time - start_time}
    except:
        pass
    return None

def main():
    unique_channels = {}
    
    for filename, url in SOURCES.items():
        try:
            print(f"ğŸŒ æ­£åœ¨åŒæ­¥: {filename}")
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            lines = r.text.split('\n')
            temp_list = []
            
            for i in range(len(lines)):
                if "#EXTINF" in lines[i] and i + 1 < len(lines):
                    name_info = lines[i].strip()
                    link = lines[i+1].strip()
                    
                    if link.startswith('http'):
                        clean_name = name_info.split(',')[-1].strip()
                        # ä»…ä¿ç•™ç¬¦åˆç”µå½±ã€ç”µè§†å‰§åŠä¸­æ–‡å…³é”®è¯çš„é¢‘é“
                        if any(kw.lower() in clean_name.lower() for kw in KEYWORDS):
                            temp_list.append((name_info, link))

            # å¹¶å‘æ£€æµ‹
            with ThreadPoolExecutor(max_workers=30) as executor:
                results = list(executor.map(check_url, temp_list))

            # å»é‡ï¼šåŒåé¢‘é“ä¿ç•™é€Ÿåº¦æœ€å¿«çš„
            for res in results:
                if res:
                    c_name = res["name"].split(',')[-1].strip()
                    if c_name not in unique_channels or res["speed"] < unique_channels[c_name]["speed"]:
                        unique_channels[c_name] = res
            
            print(f"âœ… {filename} ç­›é€‰å®Œæˆ")
        except Exception as e:
            print(f"âŒ {filename} å¤±è´¥: {e}")

    # ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶
    final_list = []
    for res in unique_channels.values():
        final_list.append(f"{res['name']}\n{res['url']}")

    with open("all.m3u", "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n" + "\n".join(final_list))
    
    print(f"\nğŸš€ å¤„ç†å®Œæˆï¼å·²ç”Ÿæˆå…¨è¦†ç›–åˆ—è¡¨ã€‚å½“å‰ç¨³å®šé¢‘é“æ€»æ•°: {len(final_list)}")

if __name__ == "__main__":
    main()

