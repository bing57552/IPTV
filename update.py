import requests
import time
from concurrent.futures import ThreadPoolExecutor

# 1. é…ç½®å…¨çƒå½±è§†å¤šç»´æºï¼šæ¶µç›–åŒ—ç¾ã€æ¬§æ´²ã€äºšæ´²(æ–°é©¬)åŠä¸“ä¸šå½±è§†
SOURCES = {
    "north_america": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/america.m3u",
    "europe": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/europe.m3u",
    "asia_chinese": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/asia.m3u",
    "southeast_asia": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/singapore_malaysia.m3u",
    "itv_movie_special": "https://itvlist.cc/itv.m3u",
    "global_zh": "https://iptv-org.github.io/iptv/languages/zho.m3u",
    "fanmingming_live": "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv4.m3u"
}

# 2. ç”µå½±ä¸ç”µè§†å‰§ç²¾å‡†ç­›é€‰å…³é”®è¯
KEYWORDS = ["ç”µå½±", "ç”µè§†å‰§", "å‰§åœº", "å½±é™¢", "TVB", "ç¿¡ç¿ ", "æ˜Ÿæ²³", "åä¸½", "Drama", "Movie", "ä¸­æ–‡", "åè¯­", "Channel 8", "Ué¢‘é“"]

def check_url(item):
    """è‡ªåŠ¨ç­›é€‰æœ‰æ•ˆä¸å¡é¡¿çš„ç›´æ’­æº"""
    name_info, url = item
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    try:
        start_time = time.time()
        # é’ˆå¯¹å…¨çƒçº¿è·¯ï¼Œè®¾ç½®2.0sè¶…æ—¶ï¼Œé˜²æ­¢è¯¯åˆ ä¼˜è´¨æµ·å¤–æºä½†ç¡®ä¿æµç•…æ€§
        response = requests.head(url, headers=headers, timeout=2.0, allow_redirects=True)
        end_time = time.time()
        
        # åªæœ‰è¿”å› 200 (çŠ¶æ€æ­£å¸¸) çš„é“¾æ¥ä¼šè¢«ä¿ç•™ï¼Œå®ç°è‡ªåŠ¨åˆ é™¤æ— æ•ˆæº
        if response.status_code == 200:
            return {"name": name_info, "url": url, "speed": end_time - start_time}
    except:
        pass
    return None

def main():
    # ä½¿ç”¨å­—å…¸è¿›è¡Œè‡ªåŠ¨å»é‡ï¼Œç¡®ä¿æ¯ä¸ªé¢‘é“åªä¿ç•™æœ€ä¼˜æº
    unique_channels = {}
    
    for filename, url in SOURCES.items():
        try:
            print(f"ğŸŒ æ­£åœ¨åŒæ­¥å…¨çƒèµ„æº: {filename}")
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            lines = r.text.split('\n')
            temp_list = []
            
            for i in range(len(lines)):
                if "#EXTINF" in lines[i] and i + 1 < len(lines):
                    name_info = lines[i].strip()
                    link = lines[i+1].strip()
                    
                    if link.startswith('http'):
                        clean_name = name_info.split(',')[-1].strip()
                        # ä»…ä¿ç•™åŒ…å«å½±è§†å…³é”®è¯çš„é¢‘é“
                        if any(kw.lower() in clean_name.lower() for kw in KEYWORDS):
                            temp_list.append((name_info, link))

            # å¹¶å‘æµ‹é€Ÿç­›é€‰
            with ThreadPoolExecutor(max_workers=30) as executor:
                results = list(executor.map(check_url, temp_list))

            # æ™ºèƒ½æ›´æ–°ï¼šè‹¥åŒåé¢‘é“å·²æœ‰ï¼Œåˆ™ä»…ä¿ç•™å“åº”æœ€å¿«çš„æº
            for res in results:
                if res:
                    c_name = res["name"].split(',')[-1].strip()
                    if c_name not in unique_channels or res["speed"] < unique_channels[c_name]["speed"]:
                        unique_channels[c_name] = res
            
            print(f"âœ… {filename} ç­›é€‰å®Œæˆ")
        except Exception as e:
            print(f"âŒ {filename} åŒæ­¥å¤±è´¥: {e}")

    # æ±‡æ€»ç”Ÿæˆæœ€ç»ˆçš„ all.m3u æ–‡ä»¶
    final_list = ["#EXTM3U"]
    for res in unique_channels.values():
        final_list.append(f"{res['name']}\n{res['url']}")

    with open("all.m3u", "w", encoding="utf-8") as f:
        f.write("\n".join(final_list))
    
    print(f"\nğŸš€ å¤„ç†å®Œæˆï¼å·²ç”Ÿæˆå…¨çƒå½±è§†å…¨è¦†ç›–åˆ—è¡¨ã€‚å½“å‰é¢‘é“æ€»æ•°: {len(unique_channels)}")

if __name__ == "__main__":
    main()



